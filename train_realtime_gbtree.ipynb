{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from file_config.config import config\n",
        "from utils.utility_preprocess import PatientFilter, LabelAssignment, DataImputation\n",
        "from utils.utility_analysis import plot_roc, plot_prc, metric_eval, line_search_best_metric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.utils import shuffle\n",
        "from imblearn.metrics import sensitivity_specificity_support\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import pickle\n",
        "import sys\n",
        "import shap\n",
        "\n",
        "\n",
        "def prepare_data(df_static, df_dynamic, dynamic_feature, args):\n",
        "\n",
        "    # label assignment (according to imputed SpO2)\n",
        "    print('Assigning labels...')\n",
        "    imputer = DataImputation()\n",
        "    df_static = imputer.impute_static_dataframe(df_static)\n",
        "    df_dynamic = imputer.impute_dynamic_dataframe(df_dynamic)\n",
        "    label_assign = LabelAssignment(hypoxemia_thresh=args.hypoxemia_thresh,\n",
        "                                   hypoxemia_window=args.hypoxemia_window,\n",
        "                                   prediction_window=args.prediction_window)\n",
        "    static_label, dynamic_label = label_assign.assign_label(df_static, df_dynamic)\n",
        "    positive_pids = label_assign.get_positive_pids(static_label)\n",
        "    print('Done.')\n",
        "\n",
        "    # get subgroup pids\n",
        "    subgroup_pids = PatientFilter(df_static=df_static,\n",
        "                                  mode=args.filter_mode,\n",
        "                                  include_icd=['J96.', 'J98.', '519.', '518.', '277.0', 'E84', 'Q31.5', '770.7',\n",
        "                                               'P27.1', '490', '491', '492', '493', '494', '495', '496', 'P27.8',\n",
        "                                               'P27.9', 'J44', 'V46.1', 'Z99.1'],  # High-risk group\n",
        "                                  exclude_icd9=['745', '746', '747'],\n",
        "                                  exclude_icd10=['Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']).filter_by_icd()\n",
        "\n",
        "    # split subgroup pids into training and test pid set\n",
        "    pid_train, pid_test, _, _ = train_test_split(static_label.loc[subgroup_pids]['pid'].values,\n",
        "                                                 static_label.loc[subgroup_pids]['label'].values,\n",
        "                                                 test_size=0.1,\n",
        "                                                 random_state=0,\n",
        "                                                 stratify=static_label.loc[subgroup_pids]['label'].values)\n",
        "    pid_train = sorted(list(pid_train))\n",
        "    pid_test = sorted(list(pid_test))\n",
        "\n",
        "    print('Positive Patient:', len(set(subgroup_pids) & set(positive_pids)), '/', len(subgroup_pids))\n",
        "    print('Before trimming:', len(positive_pids), '/', len(df_static))\n",
        "    print('Trimmed cases:', len(df_static) - len(subgroup_pids))\n",
        "\n",
        "    del df_static, df_dynamic\n",
        "\n",
        "    # select feature rows with pid in subgroup as data matrix\n",
        "    print('Training/testing split:', len(pid_train), '/', len(pid_test))\n",
        "    print('Split into training and test set...')\n",
        "    to_keep = (dynamic_label['if_to_drop'] == 0).values\n",
        "    is_in_train = dynamic_label[['pid']].isin(pid_train)['pid'].values\n",
        "    is_in_test = dynamic_label[['pid']].isin(pid_test)['pid'].values\n",
        "    selected_idx_train = list(np.where(to_keep & is_in_train)[0])\n",
        "    selected_idx_test = list(np.where(to_keep & is_in_test)[0])\n",
        "\n",
        "    # split into training and test set\n",
        "    X_train = dynamic_feature.iloc[selected_idx_train, 2:].values\n",
        "    X_test = dynamic_feature.iloc[selected_idx_test, 2:].values\n",
        "    y_train = dynamic_label.loc[selected_idx_train, 'label'].values\n",
        "    y_test = dynamic_label.loc[selected_idx_test, 'label'].values\n",
        "\n",
        "    # shuffle X and y\n",
        "    X_train, y_train = shuffle(X_train, y_train,\n",
        "                               # random_state=0\n",
        "                               )\n",
        "\n",
        "    # positive number\n",
        "    num_pos = np.sum(y_train) + np.sum(y_test)\n",
        "    num_all = len(selected_idx_train) + len(selected_idx_test)\n",
        "    print('Positive samples:', num_pos, '/', num_all)\n",
        "    print('Ratio:', '%0.2f' % (num_pos/num_all*100), '%')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def train_gbtree(X_train, y_train):\n",
        "    # Training\n",
        "    print('Training model...')\n",
        "    model = XGBClassifier(objective='binary:logistic',\n",
        "                          booster='gbtree',\n",
        "                          # silent=False,\n",
        "                          # learning_rate=0.2,\n",
        "                          # n_estimators=1000,\n",
        "                          # max_depth=6,\n",
        "                          # verbosity=2\n",
        "                          )\n",
        "    model.fit(X_train, y_train,\n",
        "              # eval_metric=eval_metric,\n",
        "              # eval_set=eval_set,\n",
        "              verbose=True)\n",
        "    print('Done.')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model, X_test, y_test):\n",
        "    # Testing\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    np.savetxt('data/result/y_prob', y_prob)\n",
        "    np.savetxt('data/result/y_test', y_test)\n",
        "\n",
        "    # Evaluation\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test, y_prob)\n",
        "    prec, rec, _ = metrics.precision_recall_curve(y_test, y_prob)\n",
        "    (sensitivity, specificity, PPV, NPV, f1, acc), _ = line_search_best_metric(y_test, y_prob, spec_thresh=0.95)\n",
        "\n",
        "    print('--------------------------------------------')\n",
        "    print('Evaluation of test set:')\n",
        "    print(\"AU-ROC:\", \"%0.4f\" % metrics.auc(fpr, tpr),\n",
        "          \"AU-PRC:\", \"%0.4f\" % metrics.auc(rec, prec))\n",
        "    print(\"sensitivity:\", \"%0.4f\" % sensitivity,\n",
        "          \"specificity:\", \"%0.4f\" % specificity,\n",
        "          \"PPV:\", \"%0.4f\" % PPV,\n",
        "          \"NPV:\", \"%0.4f\" % NPV,\n",
        "          \"F1 score:\", \"%0.4f\" % f1,\n",
        "          \"accuracy:\", \"%0.4f\" % acc)\n",
        "    print('--------------------------------------------')\n",
        "\n",
        "    # plot ROC and PRC\n",
        "    plot_roc(fpr, tpr, 'data/result/roc_initial.png')\n",
        "    plot_prc(rec, prec, 'data/result/pr_initial.png')\n",
        "\n",
        "\n",
        "def model_explain(model, data_to_predict):\n",
        "\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(data_to_predict)\n",
        "    shap.summary_plot(shap_values, data_to_predict, plot_type=\"bar\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='hypoxemia prediction')\n",
        "    parser.add_argument('--hypoxemia_thresh', type=int, default=90)\n",
        "    parser.add_argument('--hypoxemia_window', type=int, default=10)\n",
        "    parser.add_argument('--prediction_window', type=int, default=5)\n",
        "    parser.add_argument('--filter_mode', type=str, default='exclude')\n",
        "    parser.add_argument('--feature_file', type=str, default='dynamic-ewm-notxt-imp.csv')\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = prepare_data(df_static=pd.read_csv(config.get('processed', 'df_static_file')),\n",
        "                                                    df_dynamic=pd.read_csv(config.get('processed', 'df_dynamic_file')),\n",
        "                                                    dynamic_feature=pd.read_csv('data/features/' + args.feature_file),\n",
        "                                                    args=args)\n",
        "    model = train_gbtree(X_train, y_train)\n",
        "    pickle.dump(model, open(config.get('processed', 'realtime_model_file'), 'wb'))\n",
        "    evaluate(model, X_test, y_test)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}